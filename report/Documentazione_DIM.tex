\documentclass[12pt,a4paper]{report}

% ─── Pacchetti ───────────────────────────────────────────────────────────────
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[provide=*,italian]{babel}
\usepackage{geometry}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{titletoc}
\usepackage{caption}
\usepackage{float}
\usepackage{multirow}

% ─── Geometria pagina ────────────────────────────────────────────────────────
\geometry{
  a4paper,
  top=2.5cm,
  bottom=2.5cm,
  left=2.5cm,
  right=2.5cm,
  headheight=15pt
}

% ─── Colori ──────────────────────────────────────────────────────────────────
\definecolor{dimblue}{RGB}{0, 0, 0}
\definecolor{dimlightblue}{RGB}{0, 0, 0}
\definecolor{dimgray}{RGB}{0, 0, 0}
\definecolor{dimboxbg}{RGB}{240, 240, 240}
\definecolor{dimboxborder}{RGB}{0, 0, 0}
\definecolor{codebackground}{RGB}{245, 245, 245}
\definecolor{codeborder}{RGB}{200, 200, 200}

% ─── Hyperref ────────────────────────────────────────────────────────────────
\hypersetup{
  colorlinks=true,
  linkcolor=black,
  urlcolor=black,
  citecolor=black,
  pdftitle={Domain Interviewer \& Modeler - Documentazione},
  pdfauthor={Luca Scorza}
}

% ─── Intestazioni capitoli ───────────────────────────────────────────────────
\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries\color{dimblue}}
  {\chaptertitlename\ \thechapter}
  {10pt}
  {\huge}

\titleformat{\section}
  {\normalfont\large\bfseries\color{dimblue}}
  {\thesection}
  {1em}
  {}

\titleformat{\subsection}
  {\normalfont\normalsize\bfseries\color{dimgray}}
  {\thesubsection}
  {1em}
  {}

\titlespacing*{\chapter}{0pt}{-20pt}{20pt}
\titlespacing*{\section}{0pt}{12pt}{6pt}
\titlespacing*{\subsection}{0pt}{8pt}{4pt}

% ─── Intestazione e piè di pagina ────────────────────────────────────────────
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\color{dimgray}\textit{Domain Interviewer \& Modeler}}
\fancyhead[R]{\small\color{dimgray}\textit{Documentazione Tecnica}}
\fancyfoot[C]{\small\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% ─── Stile box tecnico ───────────────────────────────────────────────────────
\tcbuselibrary{breakable, skins}

\newenvironment{technicalbox}[1]{%
  \begin{tcolorbox}[
    title={\strut #1},
    breakable,
    enhanced,
    colback=dimboxbg,
    colframe=dimboxborder,
    colbacktitle=dimboxborder,
    coltitle=white,
    fonttitle=\bfseries\small,
    boxrule=0.8pt,
    arc=3pt,
    left=6pt,
    right=6pt,
    top=4pt,
    bottom=4pt,
    before upper={\parskip=4pt},
  ]
}{%
  \end{tcolorbox}
}

% ─── Stile codice ────────────────────────────────────────────────────────────
\lstdefinestyle{dimcode}{
  backgroundcolor=\color{codebackground},
  frame=single,
  framerule=0.4pt,
  rulecolor=\color{codeborder},
  basicstyle=\ttfamily\small,
  breaklines=true,
  breakatwhitespace=false,
  keepspaces=true,
  showstringspaces=false,
  tabsize=2,
  xleftmargin=10pt,
  xrightmargin=10pt,
  aboveskip=8pt,
  belowskip=8pt,
}
\lstset{style=dimcode}

% ─── Stile liste ─────────────────────────────────────────────────────────────
\setlist[itemize]{leftmargin=1.5em, itemsep=2pt, topsep=4pt}
\setlist[enumerate]{leftmargin=1.5em, itemsep=2pt, topsep=4pt}

% ─── Interlinea ──────────────────────────────────────────────────────────────
\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}

% ─── Indice personalizzato ───────────────────────────────────────────────────
\titlecontents{chapter}[0em]
  {\vspace{6pt}\bfseries}
  {\thecontentslabel\quad}
  {}
  {\titlerule*[0.5pc]{.}\contentspage}

\titlecontents{section}[1.5em]
  {\small}
  {\thecontentslabel\quad}
  {}
  {\titlerule*[0.5pc]{.}\contentspage}

\titlecontents{subsection}[3em]
  {\small}
  {\thecontentslabel\quad}
  {}
  {\titlerule*[0.5pc]{.}\contentspage}

% ─── Tabelle ─────────────────────────────────────────────────────────────────
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

\captionsetup[table]{
  labelfont={bf,color=black},
  textfont=small,
  position=below,
  skip=4pt
}

% ─────────────────────────────────────────────────────────────────────────────
%  DOCUMENTO
% ─────────────────────────────────────────────────────────────────────────────
\begin{document}

% ────────────────────────────────────────────────────────────────────────────
% FRONTESPIZIO
% ────────────────────────────────────────────────────────────────────────────
\begin{titlepage}
  \centering
  \vspace*{1.5cm}

  {\Large\bfseries Università Campus Bio-Medico di Roma\par}
  \vspace{0.4cm}
  {\large Facoltà di Ingegneria\par}
  \vspace{0.2cm}
  {\large Corso di Laurea in Ingegneria dei Sistemi Intelligenti\par}

  \vspace{1.2cm}
  {\normalsize Progetto per l'insegnamento di\par}
  \vspace{0.3cm}
  {\large\bfseries Intelligent Architectures: Microservices Programming for AI\par}

  \vspace{2cm}
  \color{dimblue}\rule{\textwidth}{1.5pt}\par
  \vspace{0.5cm}
  {\Huge\bfseries Domain Interviewer \& Modeler\par}
  \vspace{0.4cm}
  {\large Agente~1 di una pipeline multi-agente per la scoperta del dominio\\e la progettazione automatica di architetture a microservizi\\tramite AI locale e workflow orchestrati\par}
  \vspace{0.5cm}
  \color{dimblue}\rule{\textwidth}{1.5pt}\par

  \vspace{2.5cm}
  \color{black}
  \begin{minipage}{0.45\textwidth}
    \raggedright
    {\bfseries Autore:}\\[4pt]
    Luca Scorza
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \raggedleft
    {\bfseries Docente:}\\[4pt]
    Prof. Floriano Caprio
  \end{minipage}

  \vfill
  {\large Anno Accademico 2025/2026\par}
\end{titlepage}

% ────────────────────────────────────────────────────────────────────────────
% INDICE
% ────────────────────────────────────────────────────────────────────────────
\tableofcontents
\thispagestyle{fancy}

% ────────────────────────────────────────────────────────────────────────────
% ELENCO FIGURE
% ────────────────────────────────────────────────────────────────────────────
\listoffigures
\thispagestyle{fancy}

% ────────────────────────────────────────────────────────────────────────────
% ELENCO TABELLE
% ────────────────────────────────────────────────────────────────────────────
\listoftables
\thispagestyle{fancy}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Executive Summary}

\section{Visione Strategica}

Il Domain Interviewer \& Modeler (DIM) è il primo agente di una pipeline multi-agente dedicata alla progettazione automatica di architetture a microservizi secondo i principi del Domain-Driven Design (DDD). Sviluppato come Agente~1 del sistema \textit{Intelligent Domain Architect Agents}, il DIM trasforma una conversazione naturale con uno stakeholder di business in un documento architetturale strutturato e in un modello JSON formale del dominio, pronti per essere consumati dagli agenti downstream.

\section{Value Proposition}

A differenza di un semplice chatbot o di un questionario statico, il DIM risolve il problema della raccolta e strutturazione dei requisiti di dominio attraverso tre pilastri fondamentali:

\begin{itemize}
  \item \textbf{Intervista Intelligente Multi-Fase:} Una catena di cinque agenti specializzati (Domain, Context, Event, Pattern, Resilience Interviewer) guida lo stakeholder attraverso le cinque fasi del Discovery DDD, ponendo una domanda alla volta e approfondendo le risposte vaghe.
  \item \textbf{Generazione Automatica del Modello:} Al termine dell'intervista, un agente DDD Analyst sintetizza l'intera conversazione in un documento architetturale Markdown strutturato secondo cinque pilastri (Strategic Analysis, Boundaries, EDA Integration, Tactical Patterns, Technical Excellence), che viene poi convertito in JSON formale da un agente JSON Coder.
  \item \textbf{Raffinamento Interattivo:} L'utente può rivedere, modificare e confermare il modello generato attraverso un flusso di Refinement conversazionale assistito da LLM, con meccanismo di Draft/Confirm/Discard.
\end{itemize}

\section{Sintesi Tecnica}

L'architettura è interamente basata su microservizi containerizzati orchestrati da Docker Compose. L'orchestrazione dei workflow di intervista, analisi e raffinamento è delegata a n8n, che coordina gli agenti LLM tramite Ollama (llama3) e gestisce lo stato conversazionale tramite Redis. L'osservabilità completa è garantita dallo stack OpenTelemetry Collector / Loki / Prometheus / Grafana, che raccoglie log e metriche da tutti i container del sistema, incluso n8n stesso.

% ────────────────────────────────────────────────────────────────────────────
\chapter{Analisi dello Scenario e Business Case}

\section{Razionale del Progetto}

In un contesto aziendale reale, la definizione del dominio applicativo e la sua suddivisione in sottodomini funzionali rappresenta il primo passo critico nella progettazione di un sistema basato su microservizi. Questo processo, tipicamente condotto manualmente da architetti esperti attraverso sessioni di Event Storming e interviste con gli stakeholder, è lungo, soggetto a bias individuali e difficilmente ripetibile in modo sistematico.

Il Domain Interviewer \& Modeler nasce per automatizzare e strutturare questa fase fondamentale: è l'agente che conduce l'intervista di scoperta del dominio, analizza le risposte e produce un modello architetturale formale secondo i principi del Domain-Driven Design.

\section{Analisi dei Pain Points}

Lo scenario tipico di una fase di discovery manuale presenta criticità strutturali:

\begin{itemize}
  \item \textbf{Raccolta non strutturata:} Le interviste con gli stakeholder producono note informali, appunti sparsi e conoscenza implicita che non viene formalizzata in un modello coerente.
  \item \textbf{Assenza di copertura sistematica:} Senza una guida strutturata, l'architetto rischia di trascurare aspetti critici come i pattern di gestione dei fallimenti (Saga), i modelli di consistenza o le esigenze di integrazione con sistemi legacy.
  \item \textbf{Dipendenza dall'esperienza individuale:} La qualità del modello di dominio dipende interamente dall'esperienza dell'architetto che conduce la sessione.
  \item \textbf{Non ripetibilità:} Due sessioni di discovery sullo stesso progetto possono produrre modelli significativamente diversi.
\end{itemize}

\section{Rischi e Impatto Operativo}

Un modello di dominio incompleto o mal definito si traduce in bounded context errati, microservizi con responsabilità sovrapposte, e un'architettura event-driven con eventi mancanti o ridondanti. Il DIM mitiga questi rischi attraverso la sistematicità della pipeline a cinque fasi, la persistenza dello stato conversazionale in Redis, e la generazione automatica di un modello JSON strutturato e revisionabile.

% ────────────────────────────────────────────────────────────────────────────
\chapter{Obiettivi e Requisiti del Sistema}

\section{Obiettivi Strategici}

Il sistema opera come agente autonomo di Domain Discovery nella pipeline di progettazione architetturale. Gli obiettivi si articolano in:

\begin{itemize}
  \item \textbf{Intervista Guidata Multi-Fase:} Conduzione automatica di un'intervista DDD strutturata in cinque fasi progressive, ciascuna gestita da un agente specializzato con competenze specifiche nel proprio pillar architetturale.
  \item \textbf{Generazione del Modello di Dominio:} Produzione automatica di un documento architetturale Markdown e della sua rappresentazione JSON strutturata, a partire dallo storico conversazionale completo.
  \item \textbf{Raffinamento Interattivo:} Supporto a un ciclo di revisione in cui lo stakeholder può modificare il modello generato attraverso conversazione naturale con un agente dedicato (JSON Patcher).
  \item \textbf{Osservabilità Completa:} Monitoraggio end-to-end di log e metriche per tutti i componenti del sistema.
\end{itemize}

\section{Requisiti Funzionali}

\textbf{1. Pipeline di Intervista a 5 Fasi:} Cinque agenti LLM specializzati (Domain, Context, Event, Pattern, Resilience Interviewer) che conducono sequenzialmente l'intervista, con transizione automatica basata su tag di completamento fase (\texttt{[FASE\_N\_COMPLETA]}).

\textbf{2. Routing Intelligente:} Un workflow di routing che determina automaticamente se instradare il messaggio dell'utente verso il Discovery Workflow (prima intervista) o verso il Refinement Workflow (modello già generato), basandosi sullo stato in Redis.

\textbf{3. Generazione Architetturale:} Due agenti in cascata --- DDD Analyst (produce il documento Markdown) e JSON Coder (lo converte in JSON strutturato) --- che processano l'intera conversazione al completamento della Fase~5.

\textbf{4. Raffinamento del Modello:} Un workflow dedicato con agente JSON Patcher che applica le modifiche richieste dall'utente al JSON architetturale esistente, e un meccanismo di Draft Decision (conferma/rifiuta) per gestire le bozze.

\textbf{5. Frontend Chat:} Interfaccia web HTML con comunicazione REST verso n8n, supporto a sessioni persistenti tramite \texttt{sessionId} e rendering differenziato per messaggi testuali e blocchi JSON architetturali.

\textbf{6. Stato Conversazionale Persistente:} Gestione dello stato tramite Redis con chiavi dedicate per fase di discovery (\texttt{discovery\_phase}), JSON architetturale (\texttt{discovery\_json}), bozze (\texttt{draft\_json}), storico chat (\texttt{chat\_history}) e stato delle bozze (\texttt{draft\_status}).

\section{Requisiti Non Funzionali}

\begin{itemize}
  \item \textbf{Osservabilità:} Raccolta centralizzata di log (Loki) e metriche (Prometheus) tramite OpenTelemetry Collector, con dashboard Grafana preconfigurate.
  \item \textbf{Privacy e Indipendenza:} Inferenza LLM completamente locale tramite Ollama. Nessun dato inviato a servizi cloud esterni.
  \item \textbf{Portabilità:} Containerizzazione completa tramite Docker Compose per ambiente self-contained e riproducibile.
  \item \textbf{Modularità:} Ogni workflow n8n è un componente autonomo richiamabile indipendentemente, con interfacce ben definite (input/output via webhook e Redis).
\end{itemize}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Stakeholder e Ruoli}

Il presente capitolo identifica gli attori, umani e sistemici, che interagiscono con il Domain Interviewer \& Modeler. Per ogni stakeholder vengono definiti il perimetro di responsabilità e le modalità di interazione con il sistema.

\section{Business Stakeholder (Utente Intervistato)}

\textbf{Ruolo:} Rappresentante del business che partecipa all'intervista di scoperta del dominio. È la fonte primaria delle informazioni sul contesto aziendale, i processi, le entità e le regole di business.

\textbf{Responsabilità:} Rispondere alle domande degli agenti intervistatori, fornire dettagli sui processi aziendali, validare e confermare (o rifiutare) il modello architetturale generato.

\textbf{Interfaccia:} Chat web (\texttt{frontend/index.html}) su browser, comunicazione asincrona tramite webhook n8n.

\section{Agenti Intervistatori (Discovery Pipeline)}

Il sistema impiega cinque agenti specializzati, ciascuno responsabile di una fase distinta dell'intervista DDD:

\begin{table}[H]
\centering
\small
\begin{tabularx}{\textwidth}{L{3.5cm} C{1.5cm} L{7.5cm}}
\toprule
\textbf{Agente} & \textbf{Fase} & \textbf{Focus} \\
\midrule
Domain Interviewer    & 1 & Strategic Analysis: Core, Generic e Supporting Subdomains \\
Context Interviewer   & 2 & Boundaries e Language: Bounded Contexts, Aggregates, Ubiquitous Language \\
Event Interviewer     & 3 & EDA Integration: Actors, Commands, Domain Events, Pub/Sub \\
Pattern Interviewer   & 4 & Coordination Styles: Choreography/Orchestration, Sagas, CQRS, Event Sourcing \\
Resilience Interviewer & 5 & Technical Excellence: Cloud Scalability, ACL, Monitoring, Security \\
\bottomrule
\end{tabularx}
\caption{Agenti Intervistatori e relative fasi}
\end{table}

\clearpage
\begin{technicalbox}{Dettaglio Tecnico: Meccanismo di Transizione tra Fasi}
Ogni agente possiede un tag di completamento fase (es. \texttt{[FASE\_1\_COMPLETA]}). Quando l'agente ritiene che la propria fase sia sufficientemente dettagliata, emette il tag nell'output. Un nodo Switch nel workflow rileva il tag e aggiorna la chiave Redis \texttt{discovery\_phase} al valore successivo, causando l'instradamento dei messaggi futuri verso l'agente della fase successiva. Prima di emettere il tag, l'agente è istruito a riassumere i risultati della propria fase e a porre la prima domanda della fase successiva, garantendo una transizione fluida.
\end{technicalbox}

\section{Agenti di Elaborazione (Post-Discovery)}

\textbf{DDD Analyst:} Agente che analizza l'intero storico conversazionale e produce il documento architetturale Markdown strutturato secondo i cinque pilastri DDD.

\textbf{JSON Coder:} Agente che converte il documento Markdown in un JSON formale con schema predefinito, preservando ogni dettaglio tecnico senza riassumere.

\textbf{JSON Patcher:} Agente del Refinement Workflow che applica le modifiche richieste dall'utente al JSON architetturale esistente, producendo un JSON aggiornato valido.

\section{Stack di Osservabilità}

\textbf{Ruolo:} Insieme di strumenti tecnici preposti al monitoraggio e alla telemetria del sistema.

\textbf{Responsabilità:} OpenTelemetry Collector raccoglie log strutturati da n8n via OTLP e log da tutti gli altri container Docker via \texttt{receiver\_creator} con \texttt{docker\_observer}, oltre a fare scraping delle metriche Redis. I segnali vengono esportati verso Loki (log) e Prometheus (metriche). Grafana visualizza i due segnali con datasource preconfigurati.

\section{Matrice di Tracciabilità Ruoli/Funzioni}

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{3cm} C{2cm} C{2.2cm} C{2.2cm} C{2.5cm} C{2.2cm}}
\toprule
\textbf{\makecell{Ruolo/\\Stakeholder}} & \textbf{Discovery} & \textbf{\makecell{Genera-\\zione}} & \textbf{\makecell{Refine-\\ment}} & \textbf{\makecell{Draft\\Mgmt}} & \textbf{\makecell{Osserva-\\bilità}} \\
\midrule
Stakeholder          & Risponde    & No          & Modifica    & \makecell{Conferma/\\Rifiuta} & No  \\
Interviewer Agents   & Intervista  & No          & No          & No               & No  \\
DDD Analyst          & No          & Genera MD   & No          & No               & No  \\
JSON Coder           & No          & \makecell{Genera\\JSON} & No          & No               & No  \\
JSON Patcher         & No          & No          & \makecell{Patcha\\JSON} & No               & No  \\
Team DevOps          & Sì          & Sì          & Sì          & Sì               & Sì  \\
\makecell[l]{Stack\\Osservabilità}  & No          & No          & No          & No               & Sì  \\
\bottomrule
\end{tabularx}
\caption{Matrice di tracciabilità Ruoli/Funzioni}
\end{table}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Architettura del Sistema}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/architettura_uS.png}
\caption{Architettura a microservizi del sistema Domain Interviewer \& Modeler}
\label{fig:architettura_microservizi}
\end{figure}

Questo capitolo descrive l'architettura logica e fisica del Domain Interviewer \& Modeler, illustrando come i moduli cooperano per garantire un servizio di domain discovery scalabile, modulare e osservabile.

\section{Visione d'Insieme}

Il DIM è un ecosistema modulare basato su microservizi containerizzati in cui ogni componente ha un compito preciso e delimitato:

\begin{itemize}
  \item \textbf{L'Orchestratore (n8n):} Motore di workflow automation che coordina l'intera pipeline di intervista, analisi e raffinamento. Gestisce i webhook HTTP, il routing dei messaggi e l'invocazione degli agenti LLM.
  \item \textbf{Lo Stato Conversazionale (Redis):} Key-value store che mantiene lo stato persistente delle sessioni: fase corrente dell'intervista, storico chat, JSON architetturali generati, bozze in attesa di conferma.
  \item \textbf{Il Cervello (Ollama):} Runtime LLM locale che esegue il modello \texttt{llama3:latest} per tutte le operazioni di ragionamento semantico: intervista, analisi, generazione e patching del modello.
  \item \textbf{L'Interfaccia (Frontend HTML):} Chat web full-screen che consente allo stakeholder di interagire con gli agenti in linguaggio naturale, con rendering differenziato per testo e JSON architetturale.
  \item \textbf{Il Supervisore (Stack Osservabilità):} Pipeline OpenTelemetry Collector $\to$ Loki/Prometheus $\to$ Grafana che raccoglie log e metriche da tutti i container.
\end{itemize}

\section{Stack Tecnologico}

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{2.8cm} L{4cm} C{1.5cm} C{1.8cm} L{3.5cm}}
\toprule
\textbf{Componente} & \textbf{Tecnologia} & \textbf{Versione} & \textbf{Porta} & \textbf{Ruolo} \\
\midrule
n8n                 & n8n Workflow Engine  & latest  & 5678  & Orchestrazione workflow \\
redis               & Redis Alpine         & alpine  & 6379  & Stato conversazionale \\
redis-exporter      & Redis Exporter       & latest  & 9121  & Metriche Redis \\
ollama              & Ollama               & latest  & 11434 & LLM locale \\
otel-collector      & OTel Collector Contrib & 0.133.0 & 4318      & Hub telemetria \\
loki                & Grafana Loki         & 3.5.0   & 3100      & Aggregazione log \\
prometheus          & Prometheus           & 2.53.0  & 9090      & Metriche \\
grafana             & Grafana              & 12.2    & 8080      & Dashboard \\
\bottomrule
\end{tabularx}
\caption{Stack tecnologico del sistema}
\end{table}

\section{I Pilastri Progettuali}

Per garantire un sistema affidabile e manutenibile, sono stati seguiti quattro principi architetturali fondamentali:

\textbf{Orchestrazione via Workflow (n8n):} Tutta la logica applicativa è espressa come workflow n8n, non come codice custom. Questo approccio garantisce visibilità totale sul flusso di esecuzione, facilità di debug e modifica senza ricompilazione, e natività nell'integrazione con servizi esterni.

\textbf{State Management Centralizzato (Redis):} Ogni informazione di stato --- fase di discovery, storico chat, JSON generati, bozze --- è persistita in Redis con chiavi strutturate per \texttt{sessionId}. Questo disaccoppia completamente lo stato dalla logica di esecuzione e abilita la ripresa di sessioni interrotte.

\textbf{Agenti Specializzati con System Prompt:} Ogni agente LLM ha un system prompt rigorosamente definito che ne delimita il ruolo, le regole di output, il focus tematico e le condizioni di completamento fase. Questa separazione garantisce che ogni agente sia un esperto focalizzato sul proprio pillar architetturale.

\textbf{Osservabilità Nativa:} L'osservabilità non è un add-on ma un componente strutturale dell'architettura, con OTel Collector che raccoglie automaticamente i log di tutti i container Docker e la telemetria OTLP di n8n.

\section{Perché queste tecnologie?}

\begin{technicalbox}{Dettaglio Tecnico: n8n, Redis e Ollama}
\textbf{n8n:} Scelto come motore di orchestrazione per la capacità di definire workflow complessi con nodi condizionali (Switch), invocazione di sub-workflow (\texttt{executeWorkflow}), integrazione nativa con LLM (nodi \texttt{lmChatOllama} e \texttt{agent}), e gestione della memoria conversazionale tramite nodi \texttt{memoryRedisChat}. La UI di n8n offre inoltre visibilità completa sull'esecuzione di ogni workflow.

\textbf{Redis:} Scelto per la gestione dello stato conversazionale grazie alla bassa latenza, al supporto TTL nativo per la scadenza automatica delle sessioni (24h), e all'integrazione nativa con i nodi n8n per operazioni GET/SET/DELETE.

\textbf{Ollama (llama3:latest):} Runtime LLM locale che garantisce inferenza privata senza dipendenza da servizi cloud. Il modello \texttt{llama3} è utilizzato con temperatura variabile per ruolo (0.4 per gli intervistatori, 0.3 per il DDD Analyst, 0.0 per il JSON Coder) e context window di 8192 token.
\end{technicalbox}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Deployment e Containerizzazione Docker}

L'intero sistema è definito in un singolo file \texttt{docker-compose.yml} che descrive tutti i microservizi e le relative dipendenze. Tutti i servizi comunicano tramite una rete Docker interna denominata \texttt{rete\_unica}.

\section{Servizi Definiti nel Docker Compose}

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{2.5cm} L{4.5cm} C{2cm} L{4.5cm}}
\toprule
\textbf{Container} & \textbf{Immagine} & \textbf{Porte} & \textbf{Volumi Principali} \\
\midrule
loki          & grafana/loki:3.5.0          & 3100         & \texttt{./loki/loki-config.yml} \\
otel-collector & otel/opentelemetry-\newline collector-contrib:0.133.0 & 4317, 4318 & Docker socket, config YAML \\
prometheus    & prom/prometheus:v2.53.0      & 9090         & \texttt{./prometheus/prometheus.yml} \\
grafana       & grafana/grafana:\newline 12.2-ubuntu  & 8080         & Provisioning datasources \\
n8n           & docker.n8n.io/n8nio/n8n      & 5678         & \texttt{./Data\_N8N}, workflows \\
redis         & redis:alpine                 & 6379         & \texttt{./Data\_Redis} \\
redis-exporter & oliver006/redis\_exporter    & 9121         & --- \\
ollama        & ollama/ollama:latest          & 11434        & \texttt{./Data\_Ollama} \\
\bottomrule
\end{tabularx}
\caption{Dettaglio dei servizi nel Docker Compose}
\end{table}

\section{Rete e Dipendenze}

Tutti i container sono connessi alla rete bridge \texttt{rete\_unica}. Le dipendenze chiave sono:

\begin{itemize}
  \item \textbf{n8n} dipende da \texttt{redis} e \texttt{ollama} per operare correttamente. Invia inoltre telemetria nativa (log e metriche) all'OTel Collector.
  \item \textbf{otel-collector} accede al Docker socket (\texttt{/var/run/docker.sock}) per la discovery automatica dei container e la raccolta dei log tramite \texttt{receiver\_creator}, escludendo \texttt{n8n} per evitare duplicazioni dei log raccolti via OTLP.
  \item \textbf{redis-exporter} si connette a \texttt{redis:6379} per esporre le metriche in formato Prometheus.
  \item \textbf{grafana} è preconfigurato con datasource per Loki e Prometheus tramite il provisioning automatico in \texttt{grafana/provisioning/datasources/datasources.yml}.
\end{itemize}

\section{Variabili d'Ambiente n8n}

n8n è configurato per emettere log sulla console, che vengono poi raccolti dall'OpenTelemetry Collector:

\begin{lstlisting}[language=bash]
N8N_OTEL_ENABLED=true
N8N_OTEL_TRACING_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
N8N_LOG_OUTPUT=console
N8N_LOG_LEVEL=info
\end{lstlisting}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Pipeline dei Workflow n8n}

Il cuore logico del DIM è costituito da cinque workflow n8n interconnessi che implementano l'intera pipeline di discovery, analisi e raffinamento. Ogni workflow è un componente autonomo con interfacce well-defined.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/routing_locale.png}
\caption{Routing Workflow e Pipeline di Gestione dei Messaggi}
\label{fig:routing_workflow}
\end{figure}

\section{Routing Workflow}

Il Routing Workflow è il punto di ingresso dell'intera pipeline. Riceve i messaggi dallo stakeholder tramite webhook HTTP e decide dove instradadarli.

\textbf{Logica di Routing:}
\begin{enumerate}
  \item Riceve il messaggio con \texttt{sessionId} dal frontend via webhook POST.
  \item Controlla in Redis la chiave \texttt{discovery\_json:\{sessionId\}}:
  \begin{itemize}
    \item \textbf{Se NON esiste:} La discovery non è ancora completata $\to$ inoltra al Discovery Workflow.
    \item \textbf{Se esiste:} Il modello architetturale è già stato generato $\to$ inoltra al Refinement Workflow.
  \end{itemize}
  \item Restituisce la risposta dell'agente al frontend tramite webhook response.
\end{enumerate}

\section{Discovery Workflow}

Il Discovery Workflow è il componente più complesso dell'intero sistema. Implementa la pipeline di intervista a cinque fasi con agenti specializzati.

% --- Placeholder per immagine Discovery Workflow ---
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/discovery.png}
\caption{Discovery Workflow: Pipeline di intervista a 5 fasi}
\label{fig:discovery_workflow}
\end{figure}

\textbf{Flusso di Esecuzione:}
\begin{enumerate}
  \item Riceve \texttt{message} e \texttt{sessionId} dal Routing Workflow (invocazione sub-workflow).
  \item Legge la fase corrente da Redis (\texttt{discovery\_phase:\{sessionId\}}).
  \item Un nodo Switch instrada verso l'agente della fase corrente (1$\to$5).
  \item Ogni agente LLM utilizza:
  \begin{itemize}
    \item \textbf{Ollama Chat Model} con \texttt{llama3:latest} (temperatura 0.4, context 8192 token).
    \item \textbf{Redis Chat Memory} con context window crescente per fase (10$\to$20$\to$30$\to$40$\to$50 messaggi) per gestire la crescente complessità della conversazione.
  \end{itemize}
  \item Un secondo nodo Switch analizza l'output per i tag \texttt{[FASE\_N\_COMPLETA]}:
  \begin{itemize}
    \item Se il tag è presente: aggiorna la fase in Redis e restituisce la risposta.
    \item Se il tag non è presente: restituisce la risposta direttamente (la fase non cambia).
  \end{itemize}
  \item Al completamento della Fase~5 (\texttt{[FASE\_5\_COMPLETA]}): attiva la catena DDD Analyst $\to$ JSON Coder $\to$ salvataggio in Redis.
\end{enumerate}

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{3.5cm} C{1cm} C{1.8cm} C{2.2cm} L{4.5cm}}
\toprule
\textbf{Agente} & \textbf{Fase} & \textbf{Temp.} & \textbf{\makecell{Memory\\Window}} & \textbf{Tag Completamento} \\
\midrule
Domain Interviewer    & 1 & 0.4 & 10 msg & \texttt{[FASE\_1\_COMPLETA]} \\
Context Interviewer   & 2 & 0.4 & 20 msg & \texttt{[FASE\_2\_COMPLETA]} \\
Event Interviewer     & 3 & 0.4 & 30 msg & \texttt{[FASE\_3\_COMPLETA]} \\
Pattern Interviewer   & 4 & 0.4 & 40 msg & \texttt{[FASE\_4\_COMPLETA]} \\
Resilience Interviewer & 5 & 0.4 & 50 msg & \texttt{[FASE\_5\_COMPLETA]} \\
DDD Analyst           & Post & 0.3 & 200 msg & --- \\
JSON Coder            & Post & 0.0 & --- & --- \\
\bottomrule
\end{tabularx}
\caption{Configurazione degli agenti nel Discovery Workflow}
\end{table}

\section{Refinement Workflow}

Una volta generato il modello architetturale, lo stakeholder può richiedere modifiche conversazionali al JSON tramite il Refinement Workflow.

% --- Placeholder per immagine Refinement Workflow ---
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/refinement.png}
\caption{Refinement Workflow --- Modifica interattiva del modello architetturale}
\label{fig:refinement_workflow}
\end{figure}

\textbf{Flusso di Esecuzione:}
\begin{enumerate}
  \item Riceve la richiesta di modifica dall'utente e carica il JSON architetturale corrente da Redis.
  \item Un agente JSON Patcher (con system prompt dedicato) analizza la richiesta e produce un JSON aggiornato.
  \item Il JSON modificato viene salvato come ``bozza'' in Redis (\texttt{draft\_json:\{sessionId\}}) e lo stato bozza viene impostato a \texttt{pending} (\texttt{draft\_status:\{sessionId\}}).
  \item L'utente visualizza le differenze e può confermare o rifiutare la modifica.
\end{enumerate}

\section{Polling Workflow}

Il Polling Workflow implementa un meccanismo di polling lato server per verificare lo stato delle operazioni asincrone, in particolare la completezza della generazione del modello architetturale dopo la Fase~5.

\textbf{Logica:} Il frontend invia richieste periodiche al webhook di polling per verificare se il JSON architetturale è stato generato e salvato in Redis dopo il completamento della pipeline Discovery.

\section{Draft Decision Workflow}

Il Draft Decision Workflow gestisce il ciclo di vita delle bozze di modifica al modello architetturale.

\textbf{Azioni supportate:}
\begin{itemize}
  \item \textbf{Conferma (confirm):} Promuove la bozza (\texttt{draft\_json}) a versione corrente (\texttt{discovery\_json}) e rimuove lo stato bozza.
  \item \textbf{Rifiuto (discard):} Elimina la bozza e il suo stato, mantenendo la versione corrente invariata.
\end{itemize}

\begin{technicalbox}{Dettaglio Tecnico: Gestione delle Chiavi Redis}
Lo stato conversazionale del DIM è gestito tramite un insieme strutturato di chiavi Redis, tutte con namespace per \texttt{sessionId}:

\begin{tabular}{ll}
\texttt{discovery\_phase:\{sessionId\}} & Fase corrente (1--5) \\
\texttt{chat\_history:\{sessionId\}} & Storico messaggi (gestito da n8n memoryRedisChat) \\
\texttt{discovery\_json:\{sessionId\}} & Modello architetturale corrente (TTL 24h) \\
\texttt{draft\_json:\{sessionId\}} & Bozza di modifica (TTL 24h) \\
\texttt{draft\_status:\{sessionId\}} & Stato bozza: \texttt{pending} / vuoto \\
\end{tabular}
\end{technicalbox}

% ────────────────────────────────────────────────────────────────────────────
\chapter{Frontend Chat}

Il frontend è un'interfaccia web single-page (\texttt{frontend/index.html}) che consente allo stakeholder di interagire con il DIM attraverso una chat full-screen.

\section{Caratteristiche Principali}

\begin{itemize}
  \item \textbf{Chat Full-Screen:} Interfaccia a schermo intero con layout responsive, barra di input fissa in basso e area messaggi scrollabile.
  \item \textbf{Sessioni Persistenti:} Ogni sessione è identificata da un \texttt{sessionId} univoco (UUID v4) generato lato client e utilizzato per tutte le interazioni con i webhook n8n.
  \item \textbf{Rendering Differenziato:} I messaggi dell'agente vengono analizzati per individuare blocchi JSON architetturali. Quando rilevati, il JSON viene formattato e presentato in un blocco collassabile con sintassi evidenziata, separato dal testo conversazionale.
  \item \textbf{Duplice Meccanismo di Polling:} Sia dopo il completamento della Fase~5 nel Discovery (rilevato dal tag \texttt{[FASE\_5\_COMPLETA]} nella risposta) sia dopo il completamento della fase di modifica nel Refinement, il frontend avvia un polling periodico verso il Polling Workflow per attendere la generazione del modello architetturale.
  \item \textbf{Draft Management UI:} Quando l'utente riceve una bozza di modifica (durante il Refinement), vengono visualizzati pulsanti ``Conferma'' e ``Rifiuta'' che invocano il Draft Decision Workflow.
\end{itemize}

\section{Comunicazione con il Backend}

La comunicazione avviene tramite chiamate \texttt{fetch()} (REST) ai webhook n8n esposti sulla porta 5678:

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{3cm} C{1.5cm} L{4.5cm} L{4cm}}
\toprule
\textbf{Azione} & \textbf{Metodo} & \textbf{Endpoint} & \textbf{Payload} \\
\midrule
Invio messaggio   & POST & \texttt{/webhook/chat} & \texttt{message, sessionId} \\
Polling modello   & POST & \texttt{/webhook/poll} & \texttt{sessionId} \\
Draft Decision    & POST & \texttt{/webhook/draft-decision} & \texttt{sessionId, action} \\
\bottomrule
\end{tabularx}
\caption{Endpoint di comunicazione Frontend $\to$ n8n}
\end{table}


% ────────────────────────────────────────────────────────────────────────────
\chapter{Stack di Osservabilità}

L'osservabilità è un pilastro architetturale del DIM, garantendo visibilità sull'esecuzione dei workflow e sulle performance del sistema. Il sistema implementa i due pilastri fondamentali --- Log e Metriche --- attraverso una pipeline centralizzata basata su OpenTelemetry Collector.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{img/observability.png}
\caption{Architettura dello stack di osservabilità: OTel Collector $\to$ Loki / Prometheus $\to$ Grafana}
\label{fig:osservabilita}
\end{figure}

\section{OpenTelemetry Collector: L'Hub Centrale}

L'OpenTelemetry Collector (versione Contrib 0.133.0) raccoglie, processa e instrada i segnali di telemetria verso i backend appropriati.

\subsection{Receivers (Sorgenti Dati)}

Il Collector è configurato con i seguenti receiver:

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{3.5cm} L{2.5cm} L{7cm}}
\toprule
\textbf{Receiver} & \textbf{Tipo Segnale} & \textbf{Funzione} \\
\midrule
otlp (HTTP) & Log, Metriche & Riceve telemetria nativa strutturata da n8n \\
receiver\_creator\newline con filelog & Log & Scopre i container Docker tramite \texttt{docker\_observer} e raccoglie i log (escluso n8n per evitare duplicati) \\
prometheus (scrape) & Metriche & Fa scraping delle metriche di \texttt{redis-exporter:9121/metrics} \\
\bottomrule
\end{tabularx}
\caption{Receivers configurati nell'OpenTelemetry Collector}
\end{table}

\subsection{Processors (Elaborazione)}

\begin{itemize}
  \item \textbf{batch:} Raggruppa i segnali in batch per ottimizzare le operazioni di rete verso i backend.
  \item \textbf{resource:} Arricchisce i dati con attributi aggiuntivi, in particolare aggiunge l'attributo \texttt{service.name} derivato dal nome del container Docker (\texttt{container.name}) per identificare univocamente la sorgente di ogni segnale in Grafana.
\end{itemize}

\subsection{Exporters (Destinazioni)}

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{4cm} L{3cm} L{6cm}}
\toprule
\textbf{Exporter} & \textbf{Backend} & \textbf{Configurazione} \\
\midrule
loki           & Loki (3100) & Esporta log con attributi di risorsa come label Loki \\
prometheus\newline remotewrite & Prometheus (9090) & Esporta metriche via Remote Write \\
\bottomrule
\end{tabularx}
\caption{Exporters configurati nell'OpenTelemetry Collector}
\end{table}

\begin{technicalbox}{Dettaglio Tecnico: receiver\_creator e n8n logging}
L'extension \texttt{docker\_observer} si connette al Docker socket e monitora i container. Il \texttt{receiver\_creator} istanzia un receiver \texttt{filelog} per ogni container. Per ottimizzare il sistema, è stata definita una regola di esclusione: il container \texttt{agente\_interviewer\_n8n} viene ignorato dal \texttt{filelog} receiver poiché invia già i propri log in formato strutturato (arricchiti da metadati dei workflow) tramite protocollo OTLP nativo al Collector. Questo garantisce log di alta qualità senza duplicazioni.
\end{technicalbox}

\section{Loki: Aggregazione Log}

Grafana Loki (v3.5.0) è il backend di log aggregation. Configurato in modalità single-instance per sviluppo locale, riceve i log dall'OTel Collector e li rende interrogabili tramite LogQL in Grafana.

\textbf{Configurazione chiave:}
\begin{itemize}
  \item Storage su filesystem locale (\texttt{/loki/chunks}) con retention di 744 ore (31 giorni).
  \item Limite di ingestione configurato per gestire log di grandi dimensioni (10MB per messaggio gRPC).
  \item Autenticazione disabilitata per ambiente di sviluppo locale.
\end{itemize}

\section{Prometheus: Metriche}

Prometheus (v2.53.0) è il backend per le metriche. Non esegue scraping diretto dei target: le metriche arrivano esclusivamente via Remote Write dall'OTel Collector, che a sua volta fa scraping del Redis Exporter.

\textbf{Metriche disponibili:} Metriche Redis esposte dal \texttt{redis-exporter} (connessioni attive, memoria utilizzata, operazioni al secondo, chiavi per database, etc.).

\section{Grafana: Visualizzazione e Dashboard}

Grafana (v12.2) è il frontend di visualizzazione, preconfigurato tramite provisioning automatico con due datasource:

\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{L{2.3cm} L{3.2cm} C{1.5cm} L{6cm}}
\toprule
\textbf{Datasource} & \textbf{Backend} & \textbf{Default} & \textbf{Funzionalità} \\
\midrule
Loki       & \texttt{loki:3100}       & Sì & Visualizzazione log centralizzati \\
Prometheus & \texttt{prometheus:9090}  & No & PromQL per metriche Redis \\
\bottomrule
\end{tabularx}
\caption{Datasource Grafana preconfigurati}
\end{table}

% --- Placeholder per immagini dashboard Grafana ---
\begin{figure}[H]
\centering
\fbox{\parbox{0.9\textwidth}{\centering\vspace{2.5cm}\textit{Inserire qui screenshot della dashboard Grafana con log Loki}\vspace{2.5cm}}}
\caption{Dashboard Grafana --- Visualizzazione log aggregati da Loki}
\label{fig:grafana_loki}
\end{figure}


% ────────────────────────────────────────────────────────────────────────────
\chapter{Design dei System Prompt}

Il design dei system prompt è un aspetto critico del DIM. Ogni agente LLM è dotato di un system prompt ingegnerizzato secondo una struttura comune ma adattato alle specificità di ciascuna fase dell'intervista DDD.

\section{Struttura Comune dei System Prompt}

Tutti gli agenti intervistatori condividono una struttura a cinque sezioni:

\begin{enumerate}
  \item \textbf{ROLE \& PERSONA:} Definisce l'identità dell'agente come Senior Architect specializzato in un aspetto specifico del DDD. Ogni agente ha un titolo e una missione unici.
  \item \textbf{OUTPUT RULES (STRICT ENFORCEMENT):} Regole rigide che governano il comportamento dell'agente:
  \begin{itemize}
    \item Lingua: interazione esclusivamente in italiano.
    \item Dialogo diretto con il cliente, senza meta-commenti.
    \item Divieto assoluto di mostrare il ragionamento interno.
    \item Divieto di usare gergo tecnico DDD nelle domande (traduzione in scenari di business).
    \item Stile professionale, diretto e autorevole.
  \end{itemize}
  \item \textbf{BEHAVIORAL RULES:} Regole comportamentali operative:
  \begin{itemize}
    \item Una domanda alla volta.
    \item Progressione sequenziale nella propria fase.
    \item Drill-down obbligatorio su risposte vaghe.
    \item Reindirizzamento se l'utente devia verso aspetti UI/UX.
  \end{itemize}
  \item \textbf{DISCOVERY FLOW (Fase Specifica):} Definizione precisa del goal, del focus tematico e dell'anteprima della fase successiva (per il ``bridge'' nel handover).
  \item \textbf{HANDOVER RULE (Phase Completion):} Condizioni precise per emettere il tag di completamento fase, incluso l'obbligo di riassumere i risultati e porre la prima domanda della fase successiva prima del tag.
\end{enumerate}

\section{Agenti Post-Discovery}

\textbf{DDD Analyst:} Il system prompt istruisce l'agente a trasformare lo storico conversazionale in un Architectural Design Document strutturato in 5 pilastri (Strategic Analysis, Boundary Definition, EDA Integration, Tactical Patterns, Technical Excellence). Segue una ``Zero-Loss Policy'' che impone la preservazione di ogni dettaglio tecnico menzionato durante l'intervista. L'output è esclusivamente in italiano e in formato Markdown puro.

\textbf{JSON Coder:} Il system prompt definisce uno schema JSON target rigido e istruisce l'agente a eseguire una traduzione 1:1 dal Markdown al JSON, senza aggiungere, riassumere o omettere informazioni. L'output deve essere JSON valido puro, senza wrapper o commenti.

% ────────────────────────────────────────────────────────────────────────────
\chapter{Conclusioni e Sviluppi Futuri}

\section{Sintesi del Lavoro Svolto}

Il Domain Interviewer \& Modeler rappresenta l'implementazione completa dell'Agente~1 della pipeline \textit{Intelligent Domain Architect Agents}. Il sistema dimostra come sia possibile automatizzare la fase di Domain Discovery del DDD attraverso una catena di agenti LLM specializzati, orchestrati da n8n e supportati da un'infrastruttura a microservizi containerizzata e completamente osservabile.

I risultati principali del progetto sono:

\begin{itemize}
  \item \textbf{Pipeline di intervista strutturata:} Cinque agenti specializzati che coprono sistematicamente tutti i pilastri del DDD Problem Space, garantendo una copertura completa e ripetibile.
  \item \textbf{Generazione automatica del modello:} Trasformazione automatica dello storico conversazionale in un documento architetturale Markdown e in un JSON strutturato formale.
  \item \textbf{Raffinamento interattivo:} Ciclo di revisione con meccanismo Draft/Confirm/Discard che permette allo stakeholder di perfezionare iterativamente il modello generato.
  \item \textbf{Osservabilità completa:} Stack OpenTelemetry end-to-end che garantisce visibilità totale sull'esecuzione del sistema tramite log centralizzati e metriche di performance.
  \item \textbf{Privacy by design:} Inferenza LLM completamente locale tramite Ollama, senza dipendenze da servizi cloud.
\end{itemize}

\section{Sviluppi Futuri}

\begin{itemize}
  \item \textbf{Integrazione con Agente~2 e Agente~3:} Collegamento a valle con gli agenti downstream della pipeline (Requirement Analyzer, Microservice Designer) per completare la catena automatica dal domain discovery al design architetturale.
  \item \textbf{Multi-tenancy e autenticazione:} Implementazione di autenticazione utente e isolamento delle sessioni per supportare l'uso simultaneo da parte di più stakeholder.
  \item \textbf{Miglioramento dei modelli LLM:} Sostituzione di llama3 con modelli più potenti o fine-tuned per il dominio DDD, potenzialmente con supporto a context window più ampie per gestire interviste più lunghe.
  \item \textbf{Dashboard di osservabilità dedicate:} Creazione di dashboard Grafana specifiche per il monitoraggio delle performance degli agenti LLM (latenza per fase, qualità delle risposte, tasso di drill-down).
  \item \textbf{Export e integrazione:} Esportazione del modello JSON in formati standard (AsyncAPI, EventCatalog) per integrazione diretta con strumenti di sviluppo e documentazione architetturale.
\end{itemize}

\end{document}
