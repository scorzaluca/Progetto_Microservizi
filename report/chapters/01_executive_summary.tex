% ────────────────────────────────────────────────────────────────────────────
\chapter{Executive Summary}
% ────────────────────────────────────────────────────────────────────────────

\section{Visione Strategica}

Il \textbf{Domain Interviewer \& Modeler} (DIM) è il primo agente operativo di una pipeline multi-agente denominata \textit{Intelligent Domain Architect Agents}, concepita per automatizzare la progettazione di architetture a microservizi secondo i principi del Domain-Driven Design (DDD). Il DIM affronta il problema della scoperta e strutturazione dei requisiti di dominio, trasformando una conversazione in linguaggio naturale con uno stakeholder di business in un modello architetturale formale JSON, pronto per essere consumato dagli agenti downstream della pipeline.


\section{Value Proposition}

A differenza di un semplice chatbot o di un questionario statico, il DIM risolve il problema della raccolta e strutturazione dei requisiti di dominio attraverso tre pilastri fondamentali:

\begin{itemize}
  \item \textbf{Intervista Intelligente Multi-Fase:} Una catena di cinque agenti LLM specializzati guida lo stakeholder attraverso le cinque fasi del Discovery DDD. Ogni agente è un esperto focalizzato su un singolo pillar architetturale. Un sesto agente, monitora in background la completezza informativa di ciascuna fase prima di autorizzare la transizione alla successiva.

  \item \textbf{Generazione Automatica del Modello:} Al termine dell'intervista, una catena di due agenti in cascata --- il \textit{DDD Analyst} e il \textit{JSON Coder} --- processa l'intero storico conversazionale con una politica di \textit{Zero-Loss}, preservando ogni dettaglio tecnico emerso durante l'intervista.

  \item \textbf{Raffinamento Interattivo:} L'utente può rivedere, modificare e confermare il modello generato attraverso un flusso di Refinement conversazionale assistito da LLM. Un agente \textit{Modifier} comprende i cambiamenti da applicare basandosi sulle modifiche strutturali richieste, mentre un agente \textit{Explainer} risponde a domande di chiarimento sull'architettura corrente. Un meccanismo di Draft/Confirm/Discard con double-check di sicurezza garantisce che nessuna modifica venga applicata involontariamente.
\end{itemize}

\section{Sintesi Tecnica}

L'architettura è interamente basata su \textbf{microservizi containerizzati} orchestrati da \textbf{Docker Compose}. L'orchestrazione dei workflow di intervista, analisi e raffinamento è delegata a \textbf{n8n}, che coordina gli agenti LLM tramite \textbf{Ollama} (modelli \texttt{llama3} e \texttt{qwen2.5:14b}) e gestisce lo stato conversazionale tramite \textbf{Redis}. L'interfaccia utente è una chat web full-screen sviluppata come single-page HTML con  comunicazione HTTP asincrona (REST + polling) verso i webhook n8n.

Lo stack di osservabilità, basato su \textbf{OpenTelemetry Collector}, \textbf{Loki}, \textbf{Prometheus} e \textbf{Grafana}, fornisce visibilità end-to-end su log e metriche dell'intero ecosistema.


