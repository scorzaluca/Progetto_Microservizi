# ğŸ—ï¸ Walkthrough â€” Agente DDD Interviewer (Microservizi)

Walkthrough completo del progetto: un agente conversazionale DDD basato su LLM, con architettura a microservizi e stack di osservabilitÃ  integrato.

---

## 1. Visione d'Insieme

Il sistema Ã¨ un **agente intelligente** che intervista l'utente per costruire un'architettura Domain-Driven Design. Ãˆ composto da **9 container Docker** organizzati in 3 livelli funzionali, orchestrati da **5 workflow N8N**, con osservabilitÃ  completa su logs, traces e metriche.

```mermaid
graph TB
    subgraph "ğŸŒ Presentazione"
        FE["ğŸ–¥ï¸ Frontend Chat UI<br/><i>index.html</i>"]
    end

    subgraph "âš™ï¸ Applicativo"
        N8N["ğŸ”„ N8N<br/>Orchestratore Â· :5678"]
        OLL["ğŸ§  Ollama<br/>LLM Engine Â· :11434"]
        RED["ğŸ’¾ Redis<br/>Session Store Â· :6379"]
    end

    subgraph "ğŸ“Š OsservabilitÃ "
        OTEL["ğŸ“¡ OTel Collector<br/>Hub Telemetria Â· :4317/:4318"]
        LOK["ğŸ“ Loki Â· :3100"]
        TEM["ğŸ” Tempo Â· :3200"]
        PRO["ğŸ“ˆ Prometheus Â· :9090"]
        GRA["ğŸ“Š Grafana Â· :8080"]
        REX["ğŸ“¤ Redis Exporter Â· :9121"]
    end

    FE -->|"HTTP POST"| N8N
    N8N -->|"HTTP API"| OLL
    N8N -->|"GET/SET/DEL"| RED
    N8N -.->|"OTLP :4318"| OTEL
    RED -.-> REX -.->|"Scrape :9121"| OTEL
    OTEL -->|"Logs"| LOK
    OTEL -->|"Traces"| TEM
    OTEL -->|"Metrics"| PRO
    GRA --> LOK & TEM & PRO

    style FE fill:#2563eb,stroke:#1d4ed8,color:#fff
    style N8N fill:#16a34a,stroke:#15803d,color:#fff
    style OLL fill:#9333ea,stroke:#7e22ce,color:#fff
    style RED fill:#dc2626,stroke:#b91c1c,color:#fff
    style OTEL fill:#ea580c,stroke:#c2410c,color:#fff
    style LOK fill:#eab308,stroke:#ca8a04,color:#000
    style TEM fill:#0ea5e9,stroke:#0284c7,color:#fff
    style PRO fill:#e11d48,stroke:#be123c,color:#fff
    style GRA fill:#f97316,stroke:#ea580c,color:#fff
    style REX fill:#991b1b,stroke:#7f1d1d,color:#fff
```

> [!TIP]
> Un diagramma HTML interattivo e piÃ¹ dettagliato Ã¨ disponibile in [architecture_diagram.html](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/architecture_diagram.html) â€” aprilo nel browser.

---

## 2. Livello Applicativo â€” I 3 Servizi Core

### 2.1 N8N â€” Orchestratore Workflow

**Container**: `agente_interviewer_n8n` Â· **Porta**: `5678` Â· **Immagine**: `docker.n8n.io/n8nio/n8n`

N8N Ã¨ il cervello del sistema. Espone webhook HTTP che il frontend chiama, e orchestra tutta la logica dell'agente tramite 5 workflow (descritto in Â§3). Comunica con:

| Verso | Come | PerchÃ© |
|---|---|---|
| Ollama | HTTP API `:11434` | Inferenza LLM (domande DDD, generazione architettura) |
| Redis | Redis Protocol `:6379` | Stato sessione, chat history, JSON architettura |
| OTel Collector | OTLP HTTP `:4318` | Emette logs strutturati, traces e metriche |

Configurazione chiave da [docker-compose.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/docker-compose.yml#L86-L103):
- `OTEL_COLLECTOR_URL=http://otel-collector:4318` â€” abilita telemetria OTLP nativa
- `GENERIC_TIMEZONE=Europe/Rome` â€” timezone per scheduling
- Dipende da `redis`, `ollama`, `otel-collector`

### 2.2 Ollama â€” LLM Engine

**Container**: `agente_interviewer_ollama` Â· **Porta**: `11434` Â· **Immagine**: `ollama/ollama`

Esegue inferenza locale di modelli linguistici. Non ha dipendenze da altri servizi â€” Ã¨ un servizio stateless che risponde a chiamate HTTP. I dati del modello sono persistiti nel volume `Data_Ollama`.

### 2.3 Redis â€” Session Store

**Container**: `agente_interviewer_redis` Â· **Porta**: `6379` Â· **Immagine**: `redis:alpine`

Redis Ã¨ il **data layer** del sistema. Memorizza tutto lo stato conversazionale con queste chiavi:

| Chiave Redis | Tipo | Scopo |
|---|---|---|
| `discovery_json:{sessionId}` | String (JSON) | Architettura DDD corrente della sessione |
| `discovery_phase:{sessionId}` | String | Fase dell'intervista Discovery |
| `chat_history_refinement:{sessionId}` | String | Storia conversazionale del refinement |
| `draft_json:{sessionId}` | String (JSON) | Bozza di modifica proposta dal Modifier |
| `draft_status:{sessionId}` | String | Stato del draft (`failed` se bloccato) |

---

## 3. Pipeline dei Workflow N8N

Il cuore logico dell'agente Ã¨ composto da **5 workflow** che implementano un pattern di orchestrazione event-driven.

```mermaid
flowchart TD
    subgraph "1ï¸âƒ£ ROUTING"
        R_WH["Webhook POST<br/>/chat-locale"] --> R_CHK["Redis: esiste<br/>discovery_json?"]
        R_CHK -->|"No"| R_PHASE["Check/Set<br/>discovery_phase"]
        R_CHK -->|"SÃ¬"| REF
    end

    subgraph "2ï¸âƒ£ DISCOVERY"
        DISC["Intervista DDD<br/>multi-turn con Ollama"]
        DISC --> DISC_SAVE["Redis SET<br/>discovery_json"]
    end

    subgraph "3ï¸âƒ£ REFINEMENT"
        REF["Switch: action?"]
        REF -->|"explain"| EXP["Explainer Agent<br/>risponde domande"]
        REF -->|"modify"| MOD["Modifier Agent<br/>genera draft"]
        MOD --> MOD_SAVE["Redis SET<br/>draft_json"]
    end

    subgraph "4ï¸âƒ£ POLLING"
        POLL_WH["Webhook GET<br/>/check-status-locale"]
        POLL_WH --> POLL_R["Redis GET<br/>discovery_json<br/>draft_json<br/>draft_status"]
        POLL_R --> POLL_OUT["â†’ JSON al Frontend"]
    end

    subgraph "5ï¸âƒ£ DRAFT DECISION"
        DD_WH["Webhook POST<br/>/draft-decision-locale"]
        DD_WH --> DD_SW["Switch"]
        DD_SW -->|"conferma"| DD_OK["draft â†’ discovery_json<br/>cleanup history"]
        DD_SW -->|"rifiuta"| DD_NO["DELETE draft_json<br/>cleanup history"]
    end

    R_PHASE --> DISC

    style R_WH fill:#16a34a,color:#fff
    style DISC fill:#2563eb,color:#fff
    style REF fill:#ea580c,color:#fff
    style POLL_WH fill:#9333ea,color:#fff
    style DD_WH fill:#dc2626,color:#fff
    style DD_OK fill:#16a34a,color:#fff
    style DD_NO fill:#991b1b,color:#fff
```

### 3.1 Routing Workflow

**File**: [Routing_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/Routing_locale.json)

Entry point di ogni messaggio. Logica:

1. **Webhook** riceve `POST /chat-locale` con `{message, sessionId, action}`
2. **Redis GET** `discovery_json:{sessionId}` â€” controlla se esiste un'architettura
3. **IF** non esiste â†’ prima volta â†’ controlla/setta `discovery_phase` â†’ chiama **Discovery**
4. **IF** esiste â†’ architettura giÃ  generata â†’ chiama **Refinement** con l'`action` (explain/modify)

### 3.2 Discovery Workflow

**File**: [DISCOVERY WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/DISCOVERY%20WORKFLOW_locale.json)

Il workflow piÃ¹ complesso (~60KB). Implementa un'intervista multi-turn:

- L'agente LLM (Ollama) pone domande strutturate su Bounded Contexts, Entities, Aggregates, Value Objects, Domain Events
- Ogni turno di conversazione Ã¨ persistito in Redis
- Al termine, genera un **documento architetturale JSON** + un **documento Markdown** di spiegazione
- Salva il risultato come `discovery_json:{sessionId}`
- Il frontend riceve il risultato via **Polling Workflow**

### 3.3 Refinement Workflow

**File**: [REFINEMENT WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/REFINEMENT%20WORKFLOW_locale.json)

Gestisce la fase post-discovery con due percorsi:

| Azione | Agente | Output |
|---|---|---|
| `explain` | Explainer | Risposta testuale â†’ direttamente al frontend |
| `modify` | Modifier | Draft JSON â†’ `draft_json` in Redis â†’ polling â†’ bottoni conferma/rifiuto |

Il Modifier include **safety checks** che validano l'integritÃ  strutturale dell'architettura. Se falliscono, `draft_status` = `failed`.

### 3.4 Polling Workflow

**File**: [POLLING WORKFLOW_LOCALE.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/POLLING%20WORKFLOW_LOCALE.json)

Il frontend chiama `GET /check-status-locale?sessionId=...` ogni 3 secondi. Il workflow legge 3 chiavi Redis in sequenza e restituisce:

```json
{
  "discovery_json": "..." | null,
  "draft_json": "..." | null,
  "draft_status": "failed" | null
}
```

### 3.5 Draft Decision Workflow

**File**: [DRAFT DECISION WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/DRAFT%20DECISION%20WORKFLOW_locale.json)

Meccanismo **safe-lock** con doppia conferma nel frontend:

- **Conferma**: `Redis GET draft_json` â†’ `Redis SET discovery_json` (promuove) â†’ cancella `chat_history_refinement`
- **Rifiuta**: `Redis DEL draft_json` â†’ cancella `chat_history_refinement`

---

## 4. Frontend Chat UI

**File**: [index.html](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/frontend/index.html) Â· **~960 righe** HTML/CSS/JS integrati

```mermaid
stateDiagram-v2
    [*] --> Discovery: Primo messaggio
    Discovery --> ModeSelection: Architettura generata

    state ModeSelection {
        [*] --> Choose
        Choose --> Explain: "Chiedi Spiegazione"
        Choose --> Modify: "Richiedi Modifica"
    }

    Explain --> ModeSelection: Risposta ricevuta
    Modify --> DraftReview: Draft generato

    state DraftReview {
        [*] --> Confirm_or_Reject
        Confirm_or_Reject --> DoubleCheck: Click
        DoubleCheck --> Applied: "SÃ¬"
        DoubleCheck --> Confirm_or_Reject: "No"
    }

    DraftReview --> ModeSelection: Decisione presa
```

### Flusso UX

1. **Discovery** â€” L'utente descrive il dominio, l'agente intervista. Animazione "Generazione in corso..." durante l'elaborazione. Risultato: JSON architettura + documento Markdown
2. **Mode Selection** â€” Due bottoni: "Chiedi Spiegazione" / "Richiedi Modifica". L'input Ã¨ bloccato finchÃ© non si sceglie
3. **Explain** â€” L'utente pone domande, l'agente risponde. Poi torna a Mode Selection
4. **Modify** â€” L'agente genera un draft. Appare con bottoni "Conferma"/"Rifiuta" + doppia conferma (safe-lock)
5. **Reset** â€” Bottone "Nuova Chat" resetta `sessionId` in `localStorage`

### Endpoint chiamati

| Azione | Endpoint | Metodo |
|---|---|---|
| Invio messaggio | `/webhook/chat-locale` | POST `{message, sessionId, action}` |
| Polling status | `/webhook/check-status-locale` | GET `?sessionId=...` |
| Decisione draft | `/webhook/draft-decision-locale` | POST `{action, sessionId}` |

---

## 5. Stack di OsservabilitÃ  â€” Deep Dive

Lo stack implementa i **3 pilastri** dell'osservabilitÃ : **Logs**, **Traces**, **Metrics**, con correlazione cross-segnale.

```mermaid
flowchart LR
    subgraph Sources ["ğŸ“¤ Sorgenti"]
        S1["N8N<br/>OTLP nativo"]
        S2["Docker Containers<br/>stdout/stderr"]
        S3["Redis Exporter<br/>Prometheus /metrics"]
    end

    subgraph OTel ["ğŸ“¡ OpenTelemetry Collector"]
        direction TB
        subgraph Recv ["Receivers"]
            R1["OTLP<br/>HTTP+gRPC"]
            R2["Receiver Creator<br/>Dynamic Filelog"]
            R3["Prometheus<br/>Scraper"]
        end
        subgraph Proc ["Processors"]
            P1["GroupByAttrs"]
            P2["Resource<br/>+DDD attrs"]
            P3["Batch<br/>1s / 100"]
        end
        subgraph Exp ["Exporters"]
            E1["â†’ Loki"]
            E2["â†’ Tempo"]
            E3["â†’ Prometheus"]
        end
        Recv --> Proc --> Exp
    end

    subgraph Backends ["ğŸ’¾ Storage"]
        B1["ğŸ“ Loki<br/>TSDB v13"]
        B2["ğŸ” Tempo<br/>Local+WAL"]
        B3["ğŸ“ˆ Prometheus<br/>TSDB"]
    end

    subgraph Viz ["ğŸ“Š Visualizzazione"]
        G["Grafana"]
    end

    S1 --> R1
    S2 --> R2
    S3 --> R3
    E1 --> B1
    E2 --> B2
    E3 --> B3
    G -->|"LogQL"| B1
    G -->|"TraceQL"| B2
    G -->|"PromQL"| B3
    B1 <-.->|"Logsâ†”Traces"| B2

    style S1 fill:#16a34a,color:#fff
    style S2 fill:#2496ED,color:#fff
    style S3 fill:#991b1b,color:#fff
    style R1 fill:#ea580c,color:#fff
    style R2 fill:#ea580c,color:#fff
    style R3 fill:#ea580c,color:#fff
    style P1 fill:#f59e0b,color:#000
    style P2 fill:#f59e0b,color:#000
    style P3 fill:#f59e0b,color:#000
    style E1 fill:#d97706,color:#fff
    style E2 fill:#d97706,color:#fff
    style E3 fill:#d97706,color:#fff
    style B1 fill:#eab308,color:#000
    style B2 fill:#0ea5e9,color:#fff
    style B3 fill:#e11d48,color:#fff
    style G fill:#f97316,color:#fff
```

### 5.1 OTel Collector â€” Hub Centrale

**Config**: [collector.yaml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/otel-collector/collector.yaml)

#### Docker Observer + Receiver Creator

Il meccanismo piÃ¹ sofisticato dello stack. Il `docker_observer` scopre i container via Docker socket, poi il `receiver_creator` crea **dinamicamente** un `filelog` receiver per ciascuno:

```yaml
receiver_creator/docker:
  watch_observers: [docker_observer]
  receivers:
    filelog:
      rule: type == "container" && name != "otel-collector"
      config:
        include:
          - /var/lib/docker/containers/`container_id`/`container_id`-json.log
      resource_attributes:
        container.name: '`name`'           # â†’ diventa label in Loki
        container.id: '`container_id`'
        container.image.name: '`image`'
```

- Esclude `otel-collector` per evitare feedback loop
- I log Docker JSON (`{"log":"...","stream":"stdout","time":"..."}`) vengono parsati con 3 operatori pipeline
- I resource attributes diventano **label indicizzate** in Loki

#### 3 Pipeline indipendenti

| Pipeline | Receivers | Processors | Exporters |
|---|---|---|---|
| **Logs** | `otlp` + `receiver_creator/docker` | groupbyattrs â†’ resource â†’ batch | `otlphttp/loki` + debug |
| **Traces** | `otlp` | resource â†’ batch | `otlp/tempo` + debug |
| **Metrics** | `otlp` + `prometheus` | resource â†’ batch | `prometheusremotewrite` + debug |

#### Resource Processor â€” Attributi DDD

Aggiunge a **tutti** i segnali:
- `domain = core_domain`
- `bounded_context = domain_modeling`
- `service.name = agent_1_interviewer`

### 5.2 Loki â€” Log Aggregation

**Config**: [loki-config.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/loki/loki-config.yml)

| Parametro | Valore | Significato |
|---|---|---|
| Schema | TSDB v13 | Indexing moderno e efficiente |
| Storage | Filesystem locale | `/loki/chunks` + `/loki/rules` |
| Retenzione | 7 giorni | `reject_old_samples_max_age: 168h` |
| Rate limit | 10 MB/s | `ingestion_rate_mb: 10` |
| Compactor | Ogni 10 min | Ottimizza storage |

**Label OTLP indicizzate** (dalla config `otlp_config.resource_attributes`):

`service.name` Â· `container.name` Â· `container.id` Â· `container.image.name` Â· `log.iostream` Â· `domain` Â· `bounded_context`

### 5.3 Tempo â€” Distributed Tracing

**Config**: [tempo-config.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/tempo/tempo-config.yml)

Riceve span via OTLP gRPC (`:4317`) dal Collector. Le traces provengono da N8N (ogni esecuzione workflow genera span).

- **Query Frontend SLO**: 5 secondi per search e trace-by-ID
- **Ingester**: blocchi max 5 minuti
- **Compactor**: retention blocchi 1 ora
- **Storage**: filesystem locale con WAL (Write-Ahead Log)

### 5.4 Prometheus â€” Metrics

**Config**: [prometheus.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/prometheus/prometheus.yml)

Configurazione minimale: **solo Remote Write receiver**, nessuno scraping diretto. Tutte le metriche arrivano dall'OTel Collector via `/api/v1/write`.

```yaml
# Le metriche arrivano via Remote Write dall'OTel Collector
scrape_configs: []
```

Metriche disponibili: Redis (connessioni, memoria, operazioni, keyspace, latenza) + N8N (workflow execution).

### 5.5 Grafana â€” Correlazione Cross-Segnale

**Config**: [datasources.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/grafana/provisioning/datasources/datasources.yml)

3 datasource pre-provisioned con **correlazione bidirezionale**:

```mermaid
flowchart LR
    L["ğŸ“ Loki<br/>(Default)"] <-->|"trace_id regex<br/>â†” TracesToLogs"| T["ğŸ” Tempo"]
    T -->|"Service Map<br/>datasourceUid"| P["ğŸ“ˆ Prometheus"]

    style L fill:#eab308,color:#000
    style T fill:#0ea5e9,color:#fff
    style P fill:#e11d48,color:#fff
```

| Correlazione | Meccanismo | Effetto |
|---|---|---|
| **Logs â†’ Traces** | Derived Field con regex `"trace_id":"(\w+)"` su Loki | Click su trace_id nel log â†’ apre traccia in Tempo |
| **Traces â†’ Logs** | `tracesToLogsV2` con `filterByTraceID: true` su Tempo | Da una traccia, vedi tutti i log correlati in Loki |
| **Traces â†’ Metrics** | `serviceMap.datasourceUid: prometheus` su Tempo | Service Map con dipendenze e flusso richieste |

Grafana Ã¨ configurato con accesso anonimo (`Admin`) su `http://localhost:8080`.

---

## 6. Rete e Infrastruttura Docker

### Rete bridge

Tutti i 9 container condividono la rete `rete_unica` (driver `bridge`), abilitando DNS resolution per nome servizio.

### Volumi e persistenza

| Volume | Container | Path container | Contenuto |
|---|---|---|---|
| `./Data_N8N` | N8N | `/home/node/.n8n` | Workflow, credenziali, DB N8N |
| `./Data_Ollama` | Ollama | `/root/.ollama` | Modelli LLM scaricati |
| `./Data_Redis` | Redis | `/data` | Dump RDB Redis |
| `./.runtime/data/loki` | Loki | `/loki` | Chunks, indici, regole |
| `./.runtime/data/tempo` | Tempo | `/tmp/tempo` | Blocchi trace, WAL |
| `./.runtime/data/prometheus` | Prometheus | `/prometheus` | TSDB metriche |
| `./.runtime/data/grafana` | Grafana | `/var/lib/grafana` | Dashboard, utenti |

> [!IMPORTANT]
> `Data_N8N/`, `Data_Ollama/`, `Data_Redis/` e `.runtime/` sono tutti in `.gitignore`.

### Grafo delle dipendenze (`depends_on`)

```mermaid
flowchart BT
    REDIS["Redis"] & OLLAMA["Ollama"] & OTEL["OTel Collector"] --> N8N["N8N"]
    REDIS --> REXP["Redis Exporter"]
    LOKI["Loki"] & TEMPO["Tempo"] --> OTEL
    LOKI & TEMPO & PROM["Prometheus"] --> GRAFANA["Grafana"]

    style N8N fill:#16a34a,color:#fff
    style REDIS fill:#dc2626,color:#fff
    style OLLAMA fill:#9333ea,color:#fff
    style OTEL fill:#ea580c,color:#fff
    style REXP fill:#991b1b,color:#fff
    style LOKI fill:#eab308,color:#000
    style TEMPO fill:#0ea5e9,color:#fff
    style PROM fill:#e11d48,color:#fff
    style GRAFANA fill:#f97316,color:#fff
```

### Mappa porte

| Porta | Servizio | Uso |
|---|---|---|
| `5678` | N8N | UI + Webhook API |
| `6379` | Redis | Session store |
| `8080` | Grafana | Dashboard (â†’ :3000) |
| `9090` | Prometheus | Metrics + Remote Write |
| `9121` | Redis Exporter | `/metrics` |
| `3100` | Loki | Log API + OTLP |
| `3200` | Tempo | Trace Query API |
| `4317` | OTel Collector | OTLP gRPC |
| `4318` | OTel Collector | OTLP HTTP |
| `11434` | Ollama | LLM API |

---

## 7. Struttura del Progetto

```
Progetto_Microservizi/
â”œâ”€â”€ docker-compose.yml              # 9 servizi Docker + rete bridge
â”œâ”€â”€ .gitignore                      # Esclude dati runtime e segreti
â”œâ”€â”€ README.md                       # Documentazione completa
â”œâ”€â”€ architecture_diagram.html       # Diagramma interattivo (apri nel browser)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                  # SPA Chat UI (~960 righe)
â”‚
â”œâ”€â”€ workflow/                       # 5 Workflow N8N (export JSON)
â”‚   â”œâ”€â”€ Routing_locale.json
â”‚   â”œâ”€â”€ DISCOVERY WORKFLOW_locale.json
â”‚   â”œâ”€â”€ REFINEMENT WORKFLOW_locale.json
â”‚   â”œâ”€â”€ POLLING WORKFLOW_LOCALE.json
â”‚   â””â”€â”€ DRAFT DECISION WORKFLOW_locale.json
â”‚
â”œâ”€â”€ otel-collector/
â”‚   â””â”€â”€ collector.yaml              # Receivers â†’ Processors â†’ Exporters
â”‚
â”œâ”€â”€ loki/
â”‚   â””â”€â”€ loki-config.yml             # Schema TSDB v13, OTLP labels
â”‚
â”œâ”€â”€ tempo/
â”‚   â””â”€â”€ tempo-config.yml            # OTLP distributor, local storage
â”‚
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml              # Remote Write only
â”‚
â”œâ”€â”€ grafana/provisioning/
â”‚   â”œâ”€â”€ datasources/datasources.yml # Loki + Tempo + Prometheus
â”‚   â””â”€â”€ dashboards/dashboard.yml    # Auto-provisioning
â”‚
â”œâ”€â”€ Data_N8N/                       # ğŸ”’ gitignored
â”œâ”€â”€ Data_Ollama/                    # ğŸ”’ gitignored
â”œâ”€â”€ Data_Redis/                     # ğŸ”’ gitignored
â””â”€â”€ .runtime/                       # ğŸ”’ gitignored
```
