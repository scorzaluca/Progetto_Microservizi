# ğŸ—ï¸ Walkthrough â€” Agente DDD Interviewer (Microservizi)

Walkthrough completo del progetto: un agente conversazionale DDD basato su LLM, con architettura a microservizi e stack di osservabilitÃ  integrato.

---

## 1. Visione d'Insieme

Il sistema Ã¨ un **agente intelligente** che intervista l'utente per costruire un'architettura Domain-Driven Design. Ãˆ composto da **8 container Docker** organizzati in 3 livelli funzionali, orchestrati da **5 workflow N8N**, con osservabilitÃ  completa su **Logs** e **Metriche**.

```mermaid
graph TB
    subgraph "ğŸŒ Presentazione"
        FE["ğŸ–¥ï¸ Frontend Chat UI<br/><i>index.html</i>"]
    end

    subgraph "âš™ï¸ Applicativo"
        N8N["ğŸ”„ N8N<br/>Orchestratore Â· :5678"]
        OLL["ğŸ§  Ollama<br/>LLM Engine Â· :11434"]
        RED["ğŸ’¾ Redis<br/>Session Store Â· :6379"]
    end

    subgraph "ğŸ“Š OsservabilitÃ "
        OTEL["ğŸ“¡ OTel Collector<br/>Hub Telemetria Â· :4318"]
        LOK["ğŸ“ Loki Â· :3100"]
        PRO["ğŸ“ˆ Prometheus Â· :9090"]
        GRA["ğŸ“Š Grafana Â· :8080"]
        REX["ğŸ“¤ Redis Exporter Â· :9121"]
    end

    FE -->|"HTTP POST"| N8N
    N8N -->|"HTTP API"| OLL
    N8N -->|"GET/SET/DEL"| RED
    N8N -.->|"OTLP :4318<br/>logs + metrics"| OTEL
    OTEL -.->|"Scrape :5678<br/>/metrics"| N8N
    RED -.-> REX -.->|"Scrape :9121"| OTEL
    OTEL -->|"Logs"| LOK
    OTEL -->|"Metrics"| PRO
    GRA -->|"LogQL"| LOK
    GRA -->|"PromQL"| PRO

    style FE fill:#2563eb,stroke:#1d4ed8,color:#fff
    style N8N fill:#16a34a,stroke:#15803d,color:#fff
    style OLL fill:#9333ea,stroke:#7e22ce,color:#fff
    style RED fill:#dc2626,stroke:#b91c1c,color:#fff
    style OTEL fill:#ea580c,stroke:#c2410c,color:#fff
    style LOK fill:#eab308,stroke:#ca8a04,color:#000
    style PRO fill:#e11d48,stroke:#be123c,color:#fff
    style GRA fill:#f97316,stroke:#ea580c,color:#fff
    style REX fill:#991b1b,stroke:#7f1d1d,color:#fff
```

> [!TIP]
> Un diagramma HTML interattivo e piÃ¹ dettagliato Ã¨ disponibile in [architecture_diagram.html](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/architecture_diagram.html) â€” aprilo nel browser.

---

## 2. Livello Applicativo â€” I 3 Servizi Core

### 2.1 N8N â€” Orchestratore Workflow

**Container**: `n8n` Â· **Porta**: `5678` Â· **Immagine**: `docker.n8n.io/n8nio/n8n`

N8N Ã¨ il cervello del sistema. Espone webhook HTTP che il frontend chiama, e orchestra tutta la logica dell'agente tramite 5 workflow (descritto in Â§3). Comunica con:

| Verso | Come | PerchÃ© |
|---|---|---|
| Ollama | HTTP API `:11434` | Inferenza LLM (domande DDD, generazione architettura) |
| Redis | Redis Protocol `:6379` | Stato sessione, chat history, JSON architettura |
| OTel Collector | OTLP HTTP `:4318` | Emette logs strutturati e metriche OTLP |
| OTel Collector | Prometheus `:5678/metrics` | Espone metriche applicative (workflow attivi, heap, RSS, event loop) |

Configurazione chiave da [docker-compose.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/docker-compose.yml):
- `N8N_OTEL_ENABLED=true` + `OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318` â€” telemetria OTLP nativa
- `N8N_METRICS=true` + `N8N_METRICS_INCLUDE_DEFAULT_METRICS=true` â€” endpoint Prometheus su `:5678/metrics`
- Dipende da `redis`, `ollama`, `otel-collector`

### 2.2 Ollama â€” LLM Engine

**Container**: `ollama` Â· **Porta**: `11434` Â· **Immagine**: `ollama/ollama`

Esegue inferenza locale di modelli linguistici. Non ha dipendenze da altri servizi â€” Ã¨ un servizio stateless che risponde a chiamate HTTP. I dati del modello sono persistiti nel volume `Data_Ollama`.

> [!NOTE]
> Ollama v0.16.2 non espone metriche Prometheus (`/metrics` â†’ 404). Le versioni piÃ¹ recenti supportano l'endpoint nativo.

### 2.3 Redis â€” Session Store

**Container**: `redis` Â· **Porta**: `6379` Â· **Immagine**: `redis:alpine`

Redis Ã¨ il **data layer** del sistema. Memorizza tutto lo stato conversazionale con queste chiavi:

| Chiave Redis | Tipo | Scopo |
|---|---|---|
| `discovery_json:{sessionId}` | String (JSON) | Architettura DDD corrente della sessione |
| `discovery_phase:{sessionId}` | String | Fase dell'intervista Discovery |
| `chat_history_refinement:{sessionId}` | String | Storia conversazionale del refinement |
| `draft_json:{sessionId}` | String (JSON) | Bozza di modifica proposta dal Modifier |
| `draft_status:{sessionId}` | String | Stato del draft (`failed` se bloccato) |

---

## 3. Pipeline dei Workflow N8N

Il cuore logico dell'agente Ã¨ composto da **5 workflow** che implementano un pattern di orchestrazione event-driven.

```mermaid
flowchart TD
    subgraph "1ï¸âƒ£ ROUTING"
        R_WH["Webhook POST<br/>/chat-locale"] --> R_CHK["Redis: esiste<br/>discovery_json?"]
        R_CHK -->|"No"| R_PHASE["Check/Set<br/>discovery_phase"]
        R_CHK -->|"SÃ¬"| REF
    end

    subgraph "2ï¸âƒ£ DISCOVERY"
        DISC["Intervista DDD<br/>multi-turn con Ollama"]
        DISC --> DISC_SAVE["Redis SET<br/>discovery_json"]
    end

    subgraph "3ï¸âƒ£ REFINEMENT"
        REF["Switch: action?"]
        REF -->|"explain"| EXP["Explainer Agent<br/>risponde domande"]
        REF -->|"modify"| MOD["Modifier Agent<br/>genera draft"]
        MOD --> MOD_SAVE["Redis SET<br/>draft_json"]
    end

    subgraph "4ï¸âƒ£ POLLING"
        POLL_WH["Webhook GET<br/>/check-status-locale"]
        POLL_WH --> POLL_R["Redis GET<br/>discovery_json<br/>draft_json<br/>draft_status"]
        POLL_R --> POLL_OUT["â†’ JSON al Frontend"]
    end

    subgraph "5ï¸âƒ£ DRAFT DECISION"
        DD_WH["Webhook POST<br/>/draft-decision-locale"]
        DD_WH --> DD_SW["Switch"]
        DD_SW -->|"conferma"| DD_OK["draft â†’ discovery_json<br/>cleanup history"]
        DD_SW -->|"rifiuta"| DD_NO["DELETE draft_json<br/>cleanup history"]
    end

    R_PHASE --> DISC

    style R_WH fill:#16a34a,color:#fff
    style DISC fill:#2563eb,color:#fff
    style REF fill:#ea580c,color:#fff
    style POLL_WH fill:#9333ea,color:#fff
    style DD_WH fill:#dc2626,color:#fff
    style DD_OK fill:#16a34a,color:#fff
    style DD_NO fill:#991b1b,color:#fff
```

### 3.1 Routing Workflow

**File**: [Routing_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/Routing_locale.json)

Entry point di ogni messaggio. Logica:

1. **Webhook** riceve `POST /chat-locale` con `{message, sessionId, action}`
2. **Redis GET** `discovery_json:{sessionId}` â€” controlla se esiste un'architettura
3. **IF** non esiste â†’ prima volta â†’ controlla/setta `discovery_phase` â†’ chiama **Discovery**
4. **IF** esiste â†’ architettura giÃ  generata â†’ chiama **Refinement** con l'`action` (explain/modify)

### 3.2 Discovery Workflow

**File**: [DISCOVERY WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/DISCOVERY%20WORKFLOW_locale.json)

Il workflow piÃ¹ complesso (~60KB). Implementa un'intervista multi-turn:

- L'agente LLM (Ollama) pone domande strutturate su Bounded Contexts, Entities, Aggregates, Value Objects, Domain Events
- Ogni turno di conversazione Ã¨ persistito in Redis
- Al termine, genera un **documento architetturale JSON** + un **documento Markdown** di spiegazione
- Salva il risultato come `discovery_json:{sessionId}`
- Il frontend riceve il risultato via **Polling Workflow**

### 3.3 Refinement Workflow

**File**: [REFINEMENT WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/REFINEMENT%20WORKFLOW_locale.json)

Gestisce la fase post-discovery con due percorsi:

| Azione | Agente | Output |
|---|---|---|
| `explain` | Explainer | Risposta testuale â†’ direttamente al frontend |
| `modify` | Modifier | Draft JSON â†’ `draft_json` in Redis â†’ polling â†’ bottoni conferma/rifiuto |

Il Modifier include **safety checks** che validano l'integritÃ  strutturale dell'architettura. Se falliscono, `draft_status` = `failed`.

### 3.4 Polling Workflow

**File**: [POLLING WORKFLOW_LOCALE.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/POLLING%20WORKFLOW_LOCALE.json)

Il frontend chiama `GET /check-status-locale?sessionId=...` ogni 3 secondi. Il workflow legge 3 chiavi Redis in sequenza e restituisce:

```json
{
  "discovery_json": "..." | null,
  "draft_json": "..." | null,
  "draft_status": "failed" | null
}
```

### 3.5 Draft Decision Workflow

**File**: [DRAFT DECISION WORKFLOW_locale.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/workflow/DRAFT%20DECISION%20WORKFLOW_locale.json)

Meccanismo **safe-lock** con doppia conferma nel frontend:

- **Conferma**: `Redis GET draft_json` â†’ `Redis SET discovery_json` (promuove) â†’ cancella `chat_history_refinement`
- **Rifiuta**: `Redis DEL draft_json` â†’ cancella `chat_history_refinement`

---

## 4. Frontend Chat UI

**File**: [index.html](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/frontend/index.html) Â· **~960 righe** HTML/CSS/JS integrati

```mermaid
stateDiagram-v2
    [*] --> Discovery: Primo messaggio
    Discovery --> ModeSelection: Architettura generata

    state ModeSelection {
        [*] --> Choose
        Choose --> Explain: "Chiedi Spiegazione"
        Choose --> Modify: "Richiedi Modifica"
    }

    Explain --> ModeSelection: Risposta ricevuta
    Modify --> DraftReview: Draft generato

    state DraftReview {
        [*] --> Confirm_or_Reject
        Confirm_or_Reject --> DoubleCheck: Click
        DoubleCheck --> Applied: "SÃ¬"
        DoubleCheck --> Confirm_or_Reject: "No"
    }

    DraftReview --> ModeSelection: Decisione presa
```

### Flusso UX

1. **Discovery** â€” L'utente descrive il dominio, l'agente intervista. Animazione "Generazione in corso..." durante l'elaborazione. Risultato: JSON architettura + documento Markdown
2. **Mode Selection** â€” Due bottoni: "Chiedi Spiegazione" / "Richiedi Modifica". L'input Ã¨ bloccato finchÃ© non si sceglie
3. **Explain** â€” L'utente pone domande, l'agente risponde. Poi torna a Mode Selection
4. **Modify** â€” L'agente genera un draft. Appare con bottoni "Conferma"/"Rifiuta" + doppia conferma (safe-lock)
5. **Reset** â€” Bottone "Nuova Chat" resetta `sessionId` in `localStorage`

### Endpoint chiamati

| Azione | Endpoint | Metodo |
|---|---|---|
| Invio messaggio | `/webhook/chat-locale` | POST `{message, sessionId, action}` |
| Polling status | `/webhook/check-status-locale` | GET `?sessionId=...` |
| Decisione draft | `/webhook/draft-decision-locale` | POST `{action, sessionId}` |

---

## 5. Stack di OsservabilitÃ  â€” Deep Dive

Lo stack implementa i **2 pilastri** dell'osservabilitÃ : **Logs** e **Metrics**, con pipeline centralizzata basata su OpenTelemetry Collector.

```mermaid
flowchart LR
    subgraph Sources ["ğŸ“¤ Sorgenti"]
        S1["N8N<br/>OTLP nativo"]
        S1b["N8N<br/>Prometheus /metrics"]
        S2["Docker Containers<br/>stdout/stderr"]
        S3["Redis Exporter<br/>Prometheus /metrics"]
    end

    subgraph OTel ["ğŸ“¡ OpenTelemetry Collector"]
        direction TB
        subgraph Recv ["Receivers"]
            R1["OTLP<br/>HTTP :4318"]
            R2["Receiver Creator<br/>Dynamic Filelog"]
            R3["Prometheus<br/>Scraper"]
        end
        subgraph Proc ["Processors"]
            P1["Resource<br/>+DDD attrs"]
            P2["Batch<br/>1s / 100"]
        end
        subgraph Exp ["Exporters"]
            E1["â†’ Loki"]
            E2["â†’ Prometheus"]
        end
        Recv --> Proc --> Exp
    end

    subgraph Backends ["ğŸ’¾ Storage"]
        B1["ğŸ“ Loki<br/>TSDB v13"]
        B2[" Prometheus<br/>TSDB"]
    end

    subgraph Viz ["ğŸ“Š Visualizzazione"]
        G["Grafana"]
    end

    S1 --> R1
    S1b --> R3
    S2 --> R2
    S3 --> R3
    E1 --> B1
    E2 --> B2
    G -->|"LogQL"| B1
    G -->|"PromQL"| B2

    style S1 fill:#16a34a,color:#fff
    style S1b fill:#16a34a,color:#fff
    style S2 fill:#2496ED,color:#fff
    style S3 fill:#991b1b,color:#fff
    style R1 fill:#ea580c,color:#fff
    style R2 fill:#ea580c,color:#fff
    style R3 fill:#ea580c,color:#fff
    style P1 fill:#f59e0b,color:#000
    style P2 fill:#f59e0b,color:#000
    style E1 fill:#d97706,color:#fff
    style E2 fill:#d97706,color:#fff
    style B1 fill:#eab308,color:#000
    style B2 fill:#e11d48,color:#fff
    style G fill:#f97316,color:#fff
```

### 5.1 OTel Collector â€” Hub Centrale

**Config**: [collector.yaml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/otel-collector/collector.yaml)

#### Docker Observer + Receiver Creator

Il meccanismo piÃ¹ sofisticato dello stack. Il `docker_observer` scopre i container via Docker socket, poi il `receiver_creator` crea **dinamicamente** un `filelog` receiver per ciascuno:

```yaml
receiver_creator/docker:
  watch_observers: [docker_observer]
  receivers:
    filelog:
      rule: type == "container" && name != "otel-collector"
      config:
        include:
          - /var/lib/docker/containers/`container_id`/`container_id`-json.log
      resource_attributes:
        container.name: '`name`'           # â†’ diventa label in Loki
        container.id: '`container_id`'
        container.image.name: '`image`'
```

- Esclude `otel-collector` per evitare feedback loop
- I log Docker JSON (`{"log":"...","stream":"stdout","time":"..."}`) vengono parsati con 3 operatori pipeline
- I resource attributes diventano **label indicizzate** in Loki

#### Prometheus Scraper â€” Metriche n8n & Redis

Il receiver `prometheus` fa scraping di due endpoint:

| Job | Target | Intervallo | Metriche |
|---|---|---|---|
| `redis` | `redis-exporter:9121` | 10s | Connessioni, memoria, operazioni/sec, chiavi, hit rate |
| `n8n` | `n8n:5678/metrics` | 10s | `n8n_active_workflow_count`, heap, RSS, event loop lag, active handles |

> [!NOTE]
> Ollama v0.16.2 non espone metriche Prometheus. Lo scraper Ollama Ã¨ stato rimosso per evitare errori nei log del Collector.

#### 2 Pipeline indipendenti

| Pipeline | Receivers | Processors | Exporters |
|---|---|---|---|
| **Logs** | `otlp` + `receiver_creator/docker` | resource â†’ batch | `otlphttp/loki` + debug |
| **Metrics** | `otlp` + `prometheus` | resource â†’ batch | `prometheusremotewrite` + debug |

#### Resource Processor â€” Attributi DDD

Aggiunge a **tutti** i segnali:
- `domain = core_domain`
- `bounded_context = domain_modeling`
- `service.name = agent_1_interviewer`

### 5.2 Loki â€” Log Aggregation

**Config**: [loki-config.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/loki/loki-config.yml)

| Parametro | Valore | Significato |
|---|---|---|
| Schema | TSDB v13 | Indexing moderno e efficiente |
| Storage | Filesystem locale | `/loki/chunks` + `/loki/rules` |
| Retenzione | 7 giorni | `reject_old_samples_max_age: 168h` |
| Rate limit | 10 MB/s | `ingestion_rate_mb: 10` |
| Compactor | Ogni 10 min | Ottimizza storage |

**Label OTLP indicizzate** (dalla config `otlp_config.resource_attributes`):

`service.name` Â· `container.name` Â· `container.id` Â· `container.image.name` Â· `log.iostream` Â· `domain` Â· `bounded_context`

### 5.3 Prometheus â€” Metrics Storage

**Config**: [prometheus.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/prometheus/prometheus.yml)

Configurazione minimale: **solo Remote Write receiver**, nessuno scraping diretto. Tutte le metriche arrivano dall'OTel Collector via `/api/v1/write`.

**Metriche disponibili:**

| Sorgente | Metriche Principali |
|---|---|
| **Redis** (via redis-exporter) | Connessioni attive, memoria utilizzata, operazioni/sec, chiavi per database, hit rate |
| **n8n** (via endpoint /metrics) | `n8n_active_workflow_count`, `n8n_nodejs_heap_size_used_bytes`, `n8n_process_resident_memory_bytes`, `n8n_nodejs_eventloop_lag_seconds`, `n8n_nodejs_active_handles_total` |

### 5.4 Grafana â€” Visualizzazione e Dashboard

**Config**: [datasources.yml](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/grafana/provisioning/datasources/datasources.yml)

2 datasource pre-provisioned:

```mermaid
flowchart LR
    L["ğŸ“ Loki<br/>(Default)"] --- G["ğŸ“Š Grafana<br/>:8080"]
    G --- P["ï¿½ Prometheus"]

    G -->|"LogQL"| L
    G -->|"PromQL"| P

    style L fill:#eab308,color:#000
    style P fill:#e11d48,color:#fff
    style G fill:#f97316,color:#fff
```

| Datasource | Backend | Default | Query Language |
|---|---|---|---|
| Loki | `loki:3100` | âœ… SÃ¬ | LogQL |
| Prometheus | `prometheus:9090` | No | PromQL |

**Dashboard pre-provisioned** ([observability-health.json](file:///c:/Users/emagi/Documents/agent_1/Progetto_Microservizi/grafana/provisioning/dashboards/observability-health.json)):

| Sezione | Pannelli |
|---|---|
| Stato Generale | Log totali, Redis uptime, n8n workflow attivi |
| Log | Volume per container, log stderr |
| Redis | Memoria, client connessi, comandi/sec, chiavi, hit rate |
| n8n | Uptime processo, handle attivi, memoria heap/RSS, event loop lag |
| Log Sistema | Stream completo |

Grafana Ã¨ configurato con accesso anonimo (`Admin`) su `http://localhost:8080`.

---

## 6. Rete e Infrastruttura Docker

### Rete bridge

Tutti gli 8 container condividono la rete `rete_unica` (driver `bridge`), abilitando DNS resolution per nome servizio.

### Volumi e persistenza

| Volume | Container | Path container | Contenuto |
|---|---|---|---|
| `./Data_N8N` | N8N | `/home/node/.n8n` | Workflow, credenziali, DB N8N |
| `./Data_Ollama` | Ollama | `/root/.ollama` | Modelli LLM scaricati |
| `./Data_Redis` | Redis | `/data` | Dump RDB Redis |
| `./.runtime/data/loki` | Loki | `/loki` | Chunks, indici, regole |
| `./.runtime/data/prometheus` | Prometheus | `/prometheus` | TSDB metriche |
| `./.runtime/data/grafana` | Grafana | `/var/lib/grafana` | Dashboard, utenti |

> [!IMPORTANT]
> `Data_N8N/`, `Data_Ollama/`, `Data_Redis/` e `.runtime/` sono tutti in `.gitignore`.

### Grafo delle dipendenze (`depends_on`)

```mermaid
flowchart BT
    REDIS["Redis"] & OLLAMA["Ollama"] & OTEL["OTel Collector"] --> N8N["N8N"]
    REDIS --> REXP["Redis Exporter"]
    LOKI["Loki"] --> OTEL
    LOKI & PROM["Prometheus"] --> GRAFANA["Grafana"]

    style N8N fill:#16a34a,color:#fff
    style REDIS fill:#dc2626,color:#fff
    style OLLAMA fill:#9333ea,color:#fff
    style OTEL fill:#ea580c,color:#fff
    style REXP fill:#991b1b,color:#fff
    style LOKI fill:#eab308,color:#000
    style PROM fill:#e11d48,color:#fff
    style GRAFANA fill:#f97316,color:#fff
```

### Mappa porte

| Porta | Servizio | Uso |
|---|---|---|
| `5678` | N8N | UI + Webhook API + Prometheus /metrics |
| `6379` | Redis | Session store |
| `8080` | Grafana | Dashboard (â†’ :3000) |
| `9090` | Prometheus | Metrics + Remote Write |
| `9121` | Redis Exporter | `/metrics` |
| `3100` | Loki | Log API + OTLP |
| `4318` | OTel Collector | OTLP HTTP |
| `11434` | Ollama | LLM API |

---

## 7. Struttura del Progetto

```
Progetto_Microservizi/
â”œâ”€â”€ docker-compose.yml              # 8 servizi Docker + rete bridge
â”œâ”€â”€ .gitignore                      # Esclude dati runtime e segreti
â”œâ”€â”€ README.md                       # Documentazione completa
â”œâ”€â”€ architecture_diagram.html       # Diagramma interattivo (apri nel browser)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                  # SPA Chat UI (~960 righe)
â”‚
â”œâ”€â”€ workflow/                       # 5 Workflow N8N (export JSON)
â”‚   â”œâ”€â”€ Routing_locale.json
â”‚   â”œâ”€â”€ DISCOVERY WORKFLOW_locale.json
â”‚   â”œâ”€â”€ REFINEMENT WORKFLOW_locale.json
â”‚   â”œâ”€â”€ POLLING WORKFLOW_LOCALE.json
â”‚   â””â”€â”€ DRAFT DECISION WORKFLOW_locale.json
â”‚
â”œâ”€â”€ otel-collector/
â”‚   â””â”€â”€ collector.yaml              # Receivers â†’ Processors â†’ Exporters
â”‚
â”œâ”€â”€ loki/
â”‚   â””â”€â”€ loki-config.yml             # Schema TSDB v13, OTLP labels
â”‚
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml              # Remote Write only
â”‚
â”œâ”€â”€ grafana/provisioning/
â”‚   â”œâ”€â”€ datasources/datasources.yml # Loki + Prometheus
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ dashboard.yml           # Auto-provisioning
â”‚       â””â”€â”€ observability-health.json # Dashboard pre-configurata
â”‚
â”œâ”€â”€ report/
â”‚   â””â”€â”€ Documentazione_DIM.tex      # Documentazione tecnica LaTeX
â”‚
â”œâ”€â”€ Data_N8N/                       # ğŸ”’ gitignored
â”œâ”€â”€ Data_Ollama/                    # ğŸ”’ gitignored
â”œâ”€â”€ Data_Redis/                     # ğŸ”’ gitignored
â””â”€â”€ .runtime/                       # ğŸ”’ gitignored
```
